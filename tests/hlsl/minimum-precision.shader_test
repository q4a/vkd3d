[require]
shader model >= 4.0


[pixel shader]
float4 main() : sv_target
{
    min16float4 a = {0, 1, 2, 3};
    min10float2 b = {4, 5};
    min16int3 c = {6.4, 7, 8};
    min12int d = 9.4;
    min16uint4x2 e = {14.4, 15, 16, 17, 18, 19, 20, 21};
    vector<min10float, 3> g = {22, 23, 24};
    matrix<min16uint, 3, 2> h = {25.4, 26, 27, 28, 29, 30};

    return mul(e, b) + a + c.xyzx + d + g.xxyz + h[2].xyxy;
}

[test]
draw quad
probe (0, 0) rgba (197.0, 218.0, 238.0, 257.0)

[rtv 0]
format r32g32b32a32-uint
size (2d, 640, 480)

[pixel shader]
uniform min16uint2 u;

uint4 main() : sv_target
{
    min16uint i = 0x7fff, j = 0xffff;
    return uint4(u.x + i, u.y + j, 0, 0);
}

[require]
shader model >= 4.0
shader model < 6.0

[test]
uniform 0 uint4 0 0 0 0
todo(msl) draw quad
probe (0, 0) rgbaui (0x7fff, 0xffff, 0, 0)

[require]
shader model >= 6.0

[test]
uniform 0 uint4 0 0 0 0
draw quad
probe (0, 0) rgbaui (0x7fff, 0xffffffff, 0, 0)


% The code d3dcompiler_47 produces for this appears correct, but the result
% is still zero in Windows.

[pixel shader]
uniform min16uint4 u;
uniform uint i;

uint4 main() : sv_target
{
    min16uint arr[4] = {1, 2, 0x7fff, 0xffff};
    return uint4(u.x + arr[i], u.y + arr[i + 1], 0, 0);
}

[test]
uniform 0 uint4 0 0 0 0
uniform 4 uint 2
draw quad
probe (0, 0) rgbaui (0x7fff, 0xffffffff, 0, 0)
uniform 0 uint4 0 0 0 0
uniform 4 uint 0
draw quad
probe (0, 0) rgbaui (1, 2, 0, 0)

% In SM4-5 minimum precision integers in constant buffers are treated just like
% their 32-bit counterparts.

[require]
shader model >= 4.0
shader model < 6.0

[pixel shader]
uniform min16uint4 p;
uniform min16uint3 q;
uniform min16uint2 r;
uniform min16uint s;

uint4 main() : sv_target
{
    if (p.x == 0x020001 && p.y == 0x040003 && p.z == 0x060005 && p.w == 0x080007
            && q.x == 0x120011 && q.y == 0x140013 && q.z == 0x160015
            && r.x == 0x220021 && r.y == 0x240023 && s == 0x260025)
        return 1;
    return 0;
}

[test]
uniform 0 uint4 0x020001 0x040003 0x060005 0x080007
uniform 4 uint4 0x120011 0x140013 0x160015 0x180017
uniform 8 uint4 0x220021 0x240023 0x260025 0x280027
draw quad
probe (0, 0) rgbaui(1, 1, 1, 1)

% Minimum precision types have a funny behavior with respect to stride in SM6:
% DXC allocates them assuming they're 32 bit, and the generated code first loads
% a 16-bytes row from the constant buffer and then indexes inside it; drivers
% agree that each row is indeed 16 bytes long, but disagree on the stride used
% to index within a given row; on NVIDIA and WARP the stride is 2, so the 16-bit
% values are packed in the lower half of the row and the upper half is unused;
% on AMD the stride is 4, so only the lower 16-bit word of each of the four
% 32-bit values composing a row is used. The offsets generated by DXC seem to
% hint that AMD is right here (and, in particular, Microsoft's own WARP
% implementation is wrong), but the offsets do not appear in the code, so each
% driver takes its own stance anyway. We have no choice other than to accept
% both behaviors as valid.

[require]
shader model >= 6.0

[pixel shader]
uniform min16uint4 p;
uniform min16uint3 q;
uniform min16uint2 r;
uniform min16uint s;

uint4 main() : sv_target
{
    /* On AMD the stride is 4. */
    if (p.x == 0x01 && p.y == 0x03 && p.z == 0x05 && p.w == 0x07
            && q.x == 0x11 && q.y == 0x13 && q.z == 0x15
            && r.x == 0x21 && r.y == 0x23 && s == 0x25)
        return 1;
    /* On NVIDIA and WARP the stride is 2. */
    if (p.x == 0x01 && p.y == 0x02 && p.z == 0x03 && p.w == 0x04
            && q.x == 0x11 && q.y == 0x12 && q.z == 0x13
            && r.x == 0x21 && r.y == 0x22 && s == 0x23)
        return 1;
    return 0;
}

[test]
uniform 0 uint4 0x020001 0x040003 0x060005 0x080007
uniform 4 uint4 0x120011 0x140013 0x160015 0x180017
uniform 8 uint4 0x220021 0x240023 0x260025 0x280027
draw quad
todo probe (0, 0) rgbaui(1, 1, 1, 1)
